{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "401954f8-13b0-4820-9b8e-44fbed4d5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# data types\n",
    "from typing import Dict, Tuple, List\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7ea60a2-e4bf-414f-b7cb-76f7b4f8aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data_dic(folder_path: str) -> Dict:\n",
    "    '''\n",
    "    Load CSV files from a specified folder into a dictionary of DataFrames.\n",
    "    '''\n",
    "    \n",
    "    # Use glob to get all CSV files in the folder\n",
    "    csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "    \n",
    "    # Initialize an empty dictionary to store DataFrames\n",
    "    dataframes_dic = {}\n",
    "    \n",
    "    # Loop through the list of CSV files and read each one into a DataFrame\n",
    "    for file in csv_files:\n",
    "        # Extract the file name without the folder path and extension\n",
    "        file_name = os.path.basename(file).replace('.csv', '')\n",
    "    \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "        # Store the DataFrame in the dictionary\n",
    "        dataframes_dic[file_name] = df\n",
    "    \n",
    "    # Optionally, display the keys of the dictionary to see the loaded DataFrames\n",
    "    print(dataframes_dic.keys())\n",
    "\n",
    "    return dataframes_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cc9d24e-832d-4d20-8a7e-2211cddd0fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['amex', 'United_Health', 'Amgen', 'Merck_Co', 'Walmart', 'Apple', 'Verizon_Communications', 'Intel', 'Johnson_Johnson', 'Home_Depot', 'Caterpillar', 'Visa', 'JP_Morgan_Chase', 'Disney', 'IBM', 'Honeywell', 'Nike', 'Chevron_corp', '3M', 'Microsoft', 'Boeing', 'Coca_Cola_Company', 'Salesforce', 'Goldman_Sachs', 'Cisco', 'Travelers', 'McDonalds', 'Proctor_Gamble'])\n"
     ]
    }
   ],
   "source": [
    "data = load_raw_data_dic(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d8d5f7d-3ce1-4cf6-91a4-dc724f63be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IBM = data[\"IBM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d43350da-1c72-4dd9-a0a8-62b8cf03d2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "958596"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "381*2516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1f45928-52e9-490f-90eb-dd22dda0f521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 958596 entries, 0 to 958595\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Date Time  958596 non-null  object \n",
      " 1   Open       958596 non-null  float64\n",
      " 2   High       958596 non-null  float64\n",
      " 3   Low        958596 non-null  float64\n",
      " 4   Close      958596 non-null  float64\n",
      " 5   Volume     958596 non-null  float64\n",
      " 6   Date       958596 non-null  object \n",
      " 7   Time       958596 non-null  object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 58.5+ MB\n",
      "None\n",
      "                  Date Time           Open           High            Low  \\\n",
      "count                958596  958596.000000  958596.000000  958596.000000   \n",
      "unique               958596            NaN            NaN            NaN   \n",
      "top     2010-01-04 09:35:00            NaN            NaN            NaN   \n",
      "freq                      1            NaN            NaN            NaN   \n",
      "mean                    NaN     117.038388     117.069950     117.006544   \n",
      "std                     NaN      14.964046      14.964882      14.963454   \n",
      "min                     NaN      77.169100      78.482000      75.803400   \n",
      "25%                     NaN     110.381200     110.413100     110.349250   \n",
      "50%                     NaN     117.895100     117.926000     117.865500   \n",
      "75%                     NaN     128.497100     128.531400     128.464125   \n",
      "max                     NaN     147.527000     147.574900     147.479200   \n",
      "\n",
      "                Close        Volume        Date      Time  \n",
      "count   958596.000000  9.585960e+05      958596    958596  \n",
      "unique            NaN           NaN        2516       381  \n",
      "top               NaN           NaN  2010-01-04  13:23:00  \n",
      "freq              NaN           NaN         381      2694  \n",
      "mean       117.037976  9.161522e+03         NaN       NaN  \n",
      "std         14.964092  1.233466e+04         NaN       NaN  \n",
      "min         77.169100  1.050000e+02         NaN       NaN  \n",
      "25%        110.381200  3.441000e+03         NaN       NaN  \n",
      "50%        117.895100  6.097000e+03         NaN       NaN  \n",
      "75%        128.496300  1.094600e+04         NaN       NaN  \n",
      "max        147.533900  2.589432e+06         NaN       NaN  \n",
      "             Date Time     Open     High      Low    Close   Volume  \\\n",
      "0  2010-01-04 09:35:00  85.2401  85.2789  85.1624  85.2207  42796.0   \n",
      "1  2010-01-04 09:36:00  85.2271  85.4732  85.2142  85.4343  65921.0   \n",
      "2  2010-01-04 09:37:00  85.4214  85.4732  85.3048  85.4680  60876.0   \n",
      "3  2010-01-04 09:38:00  85.4732  85.5250  85.4279  85.5056  36812.0   \n",
      "4  2010-01-04 09:39:00  85.4946  85.5056  85.4214  85.4538  29232.0   \n",
      "5  2010-01-04 09:40:00  85.4732  85.5250  85.4214  85.4214  33407.0   \n",
      "6  2010-01-04 09:41:00  85.4214  85.6092  85.4214  85.6027  35586.0   \n",
      "7  2010-01-04 09:42:00  85.5865  85.6351  85.5444  85.6027  27420.0   \n",
      "8  2010-01-04 09:43:00  85.5962  85.5962  85.5444  85.5703  13890.0   \n",
      "9  2010-01-04 09:44:00  85.5548  85.6221  85.5509  85.6221  20309.0   \n",
      "\n",
      "         Date      Time  \n",
      "0  2010-01-04  09:35:00  \n",
      "1  2010-01-04  09:36:00  \n",
      "2  2010-01-04  09:37:00  \n",
      "3  2010-01-04  09:38:00  \n",
      "4  2010-01-04  09:39:00  \n",
      "5  2010-01-04  09:40:00  \n",
      "6  2010-01-04  09:41:00  \n",
      "7  2010-01-04  09:42:00  \n",
      "8  2010-01-04  09:43:00  \n",
      "9  2010-01-04  09:44:00  \n"
     ]
    }
   ],
   "source": [
    "print(IBM.info())\n",
    "print(IBM.describe(include=\"all\"))\n",
    "print(IBM.head(381))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3814bbb-fef3-4571-8390-9987b497f120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "def clean_and_label(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Parse time, build intraday returns per day, and day-level RV + log-RV + next-day label.\"\"\"\n",
    "    df = df.copy()\n",
    "    # Parse timestamp\n",
    "    df[\"ts\"] = pd.to_datetime(df[\"Date Time\"])\n",
    "    df = df.sort_values(\"ts\").reset_index(drop=True)\n",
    "\n",
    "    # Derive 'day' as calendar date (market local time if needed)\n",
    "    df[\"day\"] = df[\"ts\"].dt.date\n",
    "\n",
    "    # Minute log returns, computed WITHIN each day (no overnight mix; no need to drop first bar)\n",
    "    df[\"log_close\"] = np.log(df[\"Close\"].astype(float))\n",
    "    df[\"ret_1m\"] = df.groupby(\"day\")[\"log_close\"].diff().fillna(0.0)\n",
    "\n",
    "    # (Optional) light winsorization for bad ticks\n",
    "    df[\"ret_1m\"] = df[\"ret_1m\"].clip(-0.05, 0.05)\n",
    "\n",
    "    # Bars per day: check consistency (mode)\n",
    "    bars_per_day = (\n",
    "        df.groupby(\"day\")[\"ret_1m\"].size().mode().iat[0]\n",
    "    )\n",
    "\n",
    "    # Drop days that don’t match the typical length (e.g., half-days) to keep things simple now\n",
    "    day_counts = df.groupby(\"day\")[\"ret_1m\"].size()\n",
    "    good_days = day_counts[day_counts == bars_per_day].index\n",
    "    df = df[df[\"day\"].isin(good_days)].copy()\n",
    "\n",
    "    # Day-level realized variance & volatility\n",
    "    agg = df.groupby(\"day\")[\"ret_1m\"].agg(\n",
    "        rv=lambda x: np.sum(np.square(x)),   # realized variance\n",
    "    ).reset_index()\n",
    "    agg[\"log_rv\"] = np.log(agg[\"rv\"].replace(0.0, 1e-12))\n",
    "\n",
    "    # Next-day target\n",
    "    agg[\"log_rv_tplus1\"] = agg[\"log_rv\"].shift(-1)\n",
    "\n",
    "    # Merge back to minute-level df (constant within the day)\n",
    "    df = df.merge(agg[[\"day\", \"rv\", \"log_rv\", \"log_rv_tplus1\"]], on=\"day\", how=\"left\")\n",
    "\n",
    "    # Drop the last day (no next-day label)\n",
    "    last_day = agg[\"day\"].iloc[-1]\n",
    "    df = df[df[\"day\"] != last_day].copy()\n",
    "\n",
    "    # Keep useful columns\n",
    "    return df[[\"ts\", \"day\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"ret_1m\", \"rv\", \"log_rv\", \"log_rv_tplus1\"]]\n",
    "\n",
    "def temporal_split_days(df: pd.DataFrame, train_frac=0.6, val_frac=0.2):\n",
    "    \"\"\"Return lists of days for train/val/test with no leakage.\"\"\"\n",
    "    days = sorted(df[\"day\"].unique())\n",
    "    n = len(days)\n",
    "    n_train = int(n * train_frac)\n",
    "    n_val = int(n * val_frac)\n",
    "    train_days = days[:n_train]\n",
    "    val_days   = days[n_train:n_train + n_val]\n",
    "    test_days  = days[n_train + n_val:]\n",
    "    return train_days, val_days, test_days\n",
    "\n",
    "def build_day_windows(\n",
    "    df: pd.DataFrame,\n",
    "    context_days: int = 21,\n",
    "    feature_cols: Tuple[str, ...] = (\"ret_1m\",),\n",
    ") -> Tuple[np.ndarray, np.ndarray, Dict]:\n",
    "    \"\"\"\n",
    "    Build samples where each X is (context_days * bars_per_day, d_in) and y is log_rv of day+1.\n",
    "    We return dense numpy arrays suitable for later tensorization.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # Get canonical bars/day\n",
    "    bars_per_day = df.groupby(\"day\")[\"ret_1m\"].size().mode().iat[0]\n",
    "\n",
    "    # Prepare per-day arrays\n",
    "    grouped = {d: g for d, g in df.groupby(\"day\")}\n",
    "    days = sorted(grouped.keys())\n",
    "\n",
    "    X_list, y_list, day_idx_list = [], [], []\n",
    "\n",
    "    for i in range(len(days) - context_days):\n",
    "        context = days[i : i + context_days]      # d−K..d\n",
    "        target_day = days[i + context_days]       # d+1\n",
    "\n",
    "        # Stack intraday features for the context\n",
    "        feats = []\n",
    "        ok = True\n",
    "        for d in context:\n",
    "            g = grouped[d]\n",
    "            if len(g) != bars_per_day:\n",
    "                ok = False; break\n",
    "            feats.append(g[list(feature_cols)].to_numpy(dtype=np.float32))\n",
    "        if not ok:\n",
    "            continue\n",
    "        Xi = np.vstack(feats)  # shape: (context_days * bars_per_day, d_in)\n",
    "\n",
    "        # Target = next-day log-RV (constant within that day)\n",
    "        y_val = grouped[target_day][\"log_rv\"].iloc[0]  # or grouped[target_day][\"log_rv_tplus1\"] on previous day\n",
    "\n",
    "        X_list.append(Xi)\n",
    "        y_list.append(y_val)\n",
    "        day_idx_list.append((context[0], context[-1], target_day))\n",
    "\n",
    "    X = np.stack(X_list, axis=0)                  # [N, T, d_in]\n",
    "    y = np.array(y_list, dtype=np.float32)        # [N]\n",
    "    meta = {\"bars_per_day\": bars_per_day, \"samples\": day_idx_list, \"features\": feature_cols}\n",
    "    return X, y, meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca141c71-fc18-491c-a8b4-2a4a82369d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure Date Time is parsed as datetime\n",
    "IBM[\"Date Time\"] = pd.to_datetime(IBM[\"Date Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f08cd24-b261-412a-8e61-b565271b46a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.date(2010, 1, 4) datetime.date(2010, 1, 5)\n",
      " datetime.date(2010, 1, 6)]\n",
      "             Date Time     Open     High      Low    Close   Volume  \\\n",
      "0  2010-01-04 09:35:00  85.2401  85.2789  85.1624  85.2207  42796.0   \n",
      "1  2010-01-04 09:36:00  85.2271  85.4732  85.2142  85.4343  65921.0   \n",
      "2  2010-01-04 09:37:00  85.4214  85.4732  85.3048  85.4680  60876.0   \n",
      "3  2010-01-04 09:38:00  85.4732  85.5250  85.4279  85.5056  36812.0   \n",
      "4  2010-01-04 09:39:00  85.4946  85.5056  85.4214  85.4538  29232.0   \n",
      "5  2010-01-04 09:40:00  85.4732  85.5250  85.4214  85.4214  33407.0   \n",
      "6  2010-01-04 09:41:00  85.4214  85.6092  85.4214  85.6027  35586.0   \n",
      "7  2010-01-04 09:42:00  85.5865  85.6351  85.5444  85.6027  27420.0   \n",
      "8  2010-01-04 09:43:00  85.5962  85.5962  85.5444  85.5703  13890.0   \n",
      "9  2010-01-04 09:44:00  85.5548  85.6221  85.5509  85.6221  20309.0   \n",
      "10 2010-01-04 09:45:00  85.6221  85.7646  85.6156  85.6804  51192.0   \n",
      "11 2010-01-04 09:46:00  85.6610  85.6804  85.6156  85.6804  23012.0   \n",
      "12 2010-01-04 09:47:00  85.6869  85.7192  85.6707  85.7128  13015.0   \n",
      "13 2010-01-04 09:48:00  85.7128  85.7581  85.6998  85.7516  26118.0   \n",
      "14 2010-01-04 09:49:00  85.7516  85.7646  85.7322  85.7581  17133.0   \n",
      "15 2010-01-04 09:50:00  85.7646  85.7970  85.6998  85.7840  59844.0   \n",
      "16 2010-01-04 09:51:00  85.7775  85.7905  85.7063  85.7322  13934.0   \n",
      "17 2010-01-04 09:52:00  85.7322  85.7646  85.5509  85.6610  69901.0   \n",
      "18 2010-01-04 09:53:00  85.6674  85.6933  85.6409  85.6545  22541.0   \n",
      "19 2010-01-04 09:54:00  85.6545  85.6998  85.6480  85.6933  13388.0   \n",
      "\n",
      "          Date      Time         day  \n",
      "0   2010-01-04  09:35:00  2010-01-04  \n",
      "1   2010-01-04  09:36:00  2010-01-04  \n",
      "2   2010-01-04  09:37:00  2010-01-04  \n",
      "3   2010-01-04  09:38:00  2010-01-04  \n",
      "4   2010-01-04  09:39:00  2010-01-04  \n",
      "5   2010-01-04  09:40:00  2010-01-04  \n",
      "6   2010-01-04  09:41:00  2010-01-04  \n",
      "7   2010-01-04  09:42:00  2010-01-04  \n",
      "8   2010-01-04  09:43:00  2010-01-04  \n",
      "9   2010-01-04  09:44:00  2010-01-04  \n",
      "10  2010-01-04  09:45:00  2010-01-04  \n",
      "11  2010-01-04  09:46:00  2010-01-04  \n",
      "12  2010-01-04  09:47:00  2010-01-04  \n",
      "13  2010-01-04  09:48:00  2010-01-04  \n",
      "14  2010-01-04  09:49:00  2010-01-04  \n",
      "15  2010-01-04  09:50:00  2010-01-04  \n",
      "16  2010-01-04  09:51:00  2010-01-04  \n",
      "17  2010-01-04  09:52:00  2010-01-04  \n",
      "18  2010-01-04  09:53:00  2010-01-04  \n",
      "19  2010-01-04  09:54:00  2010-01-04  \n"
     ]
    }
   ],
   "source": [
    "# Sort chronologically\n",
    "df_ibm = IBM.sort_values(\"Date Time\").reset_index(drop=True)\n",
    "\n",
    "# Extract the date part\n",
    "df_ibm[\"day\"] = df_ibm[\"Date Time\"].dt.date\n",
    "\n",
    "# Get the first 3 unique days\n",
    "first_3_days = df_ibm[\"day\"].unique()[:3]\n",
    "\n",
    "# Slice those days\n",
    "df_first3 = df_ibm[df_ibm[\"day\"].isin(first_3_days)].copy()\n",
    "\n",
    "# Inspect\n",
    "print(first_3_days)\n",
    "print(df_first3.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27a55f7e-b175-4ded-acfc-713ab6ded3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date Time': {0: Timestamp('2010-01-04 09:35:00'),\n",
       "  1: Timestamp('2010-01-04 09:36:00'),\n",
       "  2: Timestamp('2010-01-04 09:37:00'),\n",
       "  3: Timestamp('2010-01-04 09:38:00'),\n",
       "  4: Timestamp('2010-01-04 09:39:00'),\n",
       "  5: Timestamp('2010-01-04 09:40:00'),\n",
       "  6: Timestamp('2010-01-04 09:41:00'),\n",
       "  7: Timestamp('2010-01-04 09:42:00'),\n",
       "  8: Timestamp('2010-01-04 09:43:00'),\n",
       "  9: Timestamp('2010-01-04 09:44:00'),\n",
       "  10: Timestamp('2010-01-04 09:45:00'),\n",
       "  11: Timestamp('2010-01-04 09:46:00'),\n",
       "  12: Timestamp('2010-01-04 09:47:00'),\n",
       "  13: Timestamp('2010-01-04 09:48:00'),\n",
       "  14: Timestamp('2010-01-04 09:49:00'),\n",
       "  15: Timestamp('2010-01-04 09:50:00'),\n",
       "  16: Timestamp('2010-01-04 09:51:00'),\n",
       "  17: Timestamp('2010-01-04 09:52:00'),\n",
       "  18: Timestamp('2010-01-04 09:53:00'),\n",
       "  19: Timestamp('2010-01-04 09:54:00'),\n",
       "  20: Timestamp('2010-01-04 09:55:00'),\n",
       "  21: Timestamp('2010-01-04 09:56:00'),\n",
       "  22: Timestamp('2010-01-04 09:57:00'),\n",
       "  23: Timestamp('2010-01-04 09:58:00'),\n",
       "  24: Timestamp('2010-01-04 09:59:00'),\n",
       "  25: Timestamp('2010-01-04 10:00:00'),\n",
       "  26: Timestamp('2010-01-04 10:01:00'),\n",
       "  27: Timestamp('2010-01-04 10:02:00'),\n",
       "  28: Timestamp('2010-01-04 10:03:00'),\n",
       "  29: Timestamp('2010-01-04 10:04:00'),\n",
       "  30: Timestamp('2010-01-04 10:05:00'),\n",
       "  31: Timestamp('2010-01-04 10:06:00'),\n",
       "  32: Timestamp('2010-01-04 10:07:00'),\n",
       "  33: Timestamp('2010-01-04 10:08:00'),\n",
       "  34: Timestamp('2010-01-04 10:09:00'),\n",
       "  35: Timestamp('2010-01-04 10:10:00'),\n",
       "  36: Timestamp('2010-01-04 10:11:00'),\n",
       "  37: Timestamp('2010-01-04 10:12:00'),\n",
       "  38: Timestamp('2010-01-04 10:13:00'),\n",
       "  39: Timestamp('2010-01-04 10:14:00'),\n",
       "  40: Timestamp('2010-01-04 10:15:00'),\n",
       "  41: Timestamp('2010-01-04 10:16:00'),\n",
       "  42: Timestamp('2010-01-04 10:17:00'),\n",
       "  43: Timestamp('2010-01-04 10:18:00'),\n",
       "  44: Timestamp('2010-01-04 10:19:00'),\n",
       "  45: Timestamp('2010-01-04 10:20:00'),\n",
       "  46: Timestamp('2010-01-04 10:21:00'),\n",
       "  47: Timestamp('2010-01-04 10:22:00'),\n",
       "  48: Timestamp('2010-01-04 10:23:00'),\n",
       "  49: Timestamp('2010-01-04 10:24:00')},\n",
       " 'Open': {0: 85.2401,\n",
       "  1: 85.2271,\n",
       "  2: 85.4214,\n",
       "  3: 85.4732,\n",
       "  4: 85.4946,\n",
       "  5: 85.4732,\n",
       "  6: 85.4214,\n",
       "  7: 85.5865,\n",
       "  8: 85.5962,\n",
       "  9: 85.5548,\n",
       "  10: 85.6221,\n",
       "  11: 85.661,\n",
       "  12: 85.6869,\n",
       "  13: 85.7128,\n",
       "  14: 85.7516,\n",
       "  15: 85.7646,\n",
       "  16: 85.7775,\n",
       "  17: 85.7322,\n",
       "  18: 85.6674,\n",
       "  19: 85.6545,\n",
       "  20: 85.6933,\n",
       "  21: 85.7063,\n",
       "  22: 85.7581,\n",
       "  23: 85.8229,\n",
       "  24: 85.8617,\n",
       "  25: 85.9653,\n",
       "  26: 86.056,\n",
       "  27: 86.0106,\n",
       "  28: 86.0683,\n",
       "  29: 86.0236,\n",
       "  30: 85.9847,\n",
       "  31: 86.0624,\n",
       "  32: 86.0624,\n",
       "  33: 86.0689,\n",
       "  34: 86.0495,\n",
       "  35: 86.0754,\n",
       "  36: 86.0301,\n",
       "  37: 86.0171,\n",
       "  38: 85.9653,\n",
       "  39: 85.9783,\n",
       "  40: 85.9912,\n",
       "  41: 85.9912,\n",
       "  42: 85.9394,\n",
       "  43: 85.8941,\n",
       "  44: 85.9459,\n",
       "  45: 85.8941,\n",
       "  46: 85.9135,\n",
       "  47: 85.92,\n",
       "  48: 85.9588,\n",
       "  49: 85.9647},\n",
       " 'High': {0: 85.2789,\n",
       "  1: 85.4732,\n",
       "  2: 85.4732,\n",
       "  3: 85.525,\n",
       "  4: 85.5056,\n",
       "  5: 85.525,\n",
       "  6: 85.6092,\n",
       "  7: 85.6351,\n",
       "  8: 85.5962,\n",
       "  9: 85.6221,\n",
       "  10: 85.7646,\n",
       "  11: 85.6804,\n",
       "  12: 85.7192,\n",
       "  13: 85.7581,\n",
       "  14: 85.7646,\n",
       "  15: 85.797,\n",
       "  16: 85.7905,\n",
       "  17: 85.7646,\n",
       "  18: 85.6933,\n",
       "  19: 85.6998,\n",
       "  20: 85.7128,\n",
       "  21: 85.7646,\n",
       "  22: 85.8164,\n",
       "  23: 85.8747,\n",
       "  24: 85.9653,\n",
       "  25: 86.056,\n",
       "  26: 86.0624,\n",
       "  27: 86.0948,\n",
       "  28: 86.1013,\n",
       "  29: 86.0268,\n",
       "  30: 86.0819,\n",
       "  31: 86.0819,\n",
       "  32: 86.1013,\n",
       "  33: 86.0948,\n",
       "  34: 86.1013,\n",
       "  35: 86.0883,\n",
       "  36: 86.056,\n",
       "  37: 86.0365,\n",
       "  38: 86.0106,\n",
       "  39: 85.9912,\n",
       "  40: 86.0171,\n",
       "  41: 86.0106,\n",
       "  42: 85.9524,\n",
       "  43: 85.9653,\n",
       "  44: 85.9459,\n",
       "  45: 85.9329,\n",
       "  46: 85.9394,\n",
       "  47: 85.9718,\n",
       "  48: 85.9783,\n",
       "  49: 85.9847},\n",
       " 'Low': {0: 85.1624,\n",
       "  1: 85.2142,\n",
       "  2: 85.3048,\n",
       "  3: 85.4279,\n",
       "  4: 85.4214,\n",
       "  5: 85.4214,\n",
       "  6: 85.4214,\n",
       "  7: 85.5444,\n",
       "  8: 85.5444,\n",
       "  9: 85.5509,\n",
       "  10: 85.6156,\n",
       "  11: 85.6156,\n",
       "  12: 85.6707,\n",
       "  13: 85.6998,\n",
       "  14: 85.7322,\n",
       "  15: 85.6998,\n",
       "  16: 85.7063,\n",
       "  17: 85.5509,\n",
       "  18: 85.6409,\n",
       "  19: 85.648,\n",
       "  20: 85.6804,\n",
       "  21: 85.6869,\n",
       "  22: 85.7581,\n",
       "  23: 85.8229,\n",
       "  24: 85.8617,\n",
       "  25: 85.8617,\n",
       "  26: 85.9912,\n",
       "  27: 86.0106,\n",
       "  28: 86.0042,\n",
       "  29: 85.9524,\n",
       "  30: 85.9847,\n",
       "  31: 86.0365,\n",
       "  32: 86.0624,\n",
       "  33: 85.9524,\n",
       "  34: 86.0495,\n",
       "  35: 85.9977,\n",
       "  36: 85.9977,\n",
       "  37: 85.9653,\n",
       "  38: 85.9653,\n",
       "  39: 85.9653,\n",
       "  40: 85.9847,\n",
       "  41: 85.9394,\n",
       "  42: 85.8811,\n",
       "  43: 85.8876,\n",
       "  44: 85.8941,\n",
       "  45: 85.8876,\n",
       "  46: 85.9135,\n",
       "  47: 85.92,\n",
       "  48: 85.9524,\n",
       "  49: 85.9459},\n",
       " 'Close': {0: 85.2207,\n",
       "  1: 85.4343,\n",
       "  2: 85.468,\n",
       "  3: 85.5056,\n",
       "  4: 85.4538,\n",
       "  5: 85.4214,\n",
       "  6: 85.6027,\n",
       "  7: 85.6027,\n",
       "  8: 85.5703,\n",
       "  9: 85.6221,\n",
       "  10: 85.6804,\n",
       "  11: 85.6804,\n",
       "  12: 85.7128,\n",
       "  13: 85.7516,\n",
       "  14: 85.7581,\n",
       "  15: 85.784,\n",
       "  16: 85.7322,\n",
       "  17: 85.661,\n",
       "  18: 85.6545,\n",
       "  19: 85.6933,\n",
       "  20: 85.7128,\n",
       "  21: 85.7613,\n",
       "  22: 85.8099,\n",
       "  23: 85.8617,\n",
       "  24: 85.9653,\n",
       "  25: 86.0495,\n",
       "  26: 86.0106,\n",
       "  27: 86.0624,\n",
       "  28: 86.0236,\n",
       "  29: 85.9783,\n",
       "  30: 86.0689,\n",
       "  31: 86.0689,\n",
       "  32: 86.0754,\n",
       "  33: 86.056,\n",
       "  34: 86.0819,\n",
       "  35: 86.021,\n",
       "  36: 86.0119,\n",
       "  37: 85.9653,\n",
       "  38: 85.9718,\n",
       "  39: 85.9912,\n",
       "  40: 85.9847,\n",
       "  41: 85.9394,\n",
       "  42: 85.8876,\n",
       "  43: 85.9459,\n",
       "  44: 85.8941,\n",
       "  45: 85.907,\n",
       "  46: 85.9213,\n",
       "  47: 85.9653,\n",
       "  48: 85.9653,\n",
       "  49: 85.9783},\n",
       " 'Volume': {0: 42796.0,\n",
       "  1: 65921.0,\n",
       "  2: 60876.0,\n",
       "  3: 36812.0,\n",
       "  4: 29232.0,\n",
       "  5: 33407.0,\n",
       "  6: 35586.0,\n",
       "  7: 27420.0,\n",
       "  8: 13890.0,\n",
       "  9: 20309.0,\n",
       "  10: 51192.0,\n",
       "  11: 23012.0,\n",
       "  12: 13015.0,\n",
       "  13: 26118.0,\n",
       "  14: 17133.0,\n",
       "  15: 59844.0,\n",
       "  16: 13934.0,\n",
       "  17: 69901.0,\n",
       "  18: 22541.0,\n",
       "  19: 13388.0,\n",
       "  20: 24492.0,\n",
       "  21: 27561.0,\n",
       "  22: 37168.0,\n",
       "  23: 27261.0,\n",
       "  24: 33532.0,\n",
       "  25: 73315.0,\n",
       "  26: 30806.0,\n",
       "  27: 27114.0,\n",
       "  28: 34684.0,\n",
       "  29: 23919.0,\n",
       "  30: 23750.0,\n",
       "  31: 35286.0,\n",
       "  32: 26621.0,\n",
       "  33: 57680.0,\n",
       "  34: 25626.0,\n",
       "  35: 42039.0,\n",
       "  36: 18410.0,\n",
       "  37: 22576.0,\n",
       "  38: 26652.0,\n",
       "  39: 17259.0,\n",
       "  40: 9937.0,\n",
       "  41: 14853.0,\n",
       "  42: 15525.0,\n",
       "  43: 13453.0,\n",
       "  44: 8645.0,\n",
       "  45: 13094.0,\n",
       "  46: 22334.0,\n",
       "  47: 17048.0,\n",
       "  48: 12931.0,\n",
       "  49: 16023.0},\n",
       " 'Date': {0: '2010-01-04',\n",
       "  1: '2010-01-04',\n",
       "  2: '2010-01-04',\n",
       "  3: '2010-01-04',\n",
       "  4: '2010-01-04',\n",
       "  5: '2010-01-04',\n",
       "  6: '2010-01-04',\n",
       "  7: '2010-01-04',\n",
       "  8: '2010-01-04',\n",
       "  9: '2010-01-04',\n",
       "  10: '2010-01-04',\n",
       "  11: '2010-01-04',\n",
       "  12: '2010-01-04',\n",
       "  13: '2010-01-04',\n",
       "  14: '2010-01-04',\n",
       "  15: '2010-01-04',\n",
       "  16: '2010-01-04',\n",
       "  17: '2010-01-04',\n",
       "  18: '2010-01-04',\n",
       "  19: '2010-01-04',\n",
       "  20: '2010-01-04',\n",
       "  21: '2010-01-04',\n",
       "  22: '2010-01-04',\n",
       "  23: '2010-01-04',\n",
       "  24: '2010-01-04',\n",
       "  25: '2010-01-04',\n",
       "  26: '2010-01-04',\n",
       "  27: '2010-01-04',\n",
       "  28: '2010-01-04',\n",
       "  29: '2010-01-04',\n",
       "  30: '2010-01-04',\n",
       "  31: '2010-01-04',\n",
       "  32: '2010-01-04',\n",
       "  33: '2010-01-04',\n",
       "  34: '2010-01-04',\n",
       "  35: '2010-01-04',\n",
       "  36: '2010-01-04',\n",
       "  37: '2010-01-04',\n",
       "  38: '2010-01-04',\n",
       "  39: '2010-01-04',\n",
       "  40: '2010-01-04',\n",
       "  41: '2010-01-04',\n",
       "  42: '2010-01-04',\n",
       "  43: '2010-01-04',\n",
       "  44: '2010-01-04',\n",
       "  45: '2010-01-04',\n",
       "  46: '2010-01-04',\n",
       "  47: '2010-01-04',\n",
       "  48: '2010-01-04',\n",
       "  49: '2010-01-04'},\n",
       " 'Time': {0: '09:35:00',\n",
       "  1: '09:36:00',\n",
       "  2: '09:37:00',\n",
       "  3: '09:38:00',\n",
       "  4: '09:39:00',\n",
       "  5: '09:40:00',\n",
       "  6: '09:41:00',\n",
       "  7: '09:42:00',\n",
       "  8: '09:43:00',\n",
       "  9: '09:44:00',\n",
       "  10: '09:45:00',\n",
       "  11: '09:46:00',\n",
       "  12: '09:47:00',\n",
       "  13: '09:48:00',\n",
       "  14: '09:49:00',\n",
       "  15: '09:50:00',\n",
       "  16: '09:51:00',\n",
       "  17: '09:52:00',\n",
       "  18: '09:53:00',\n",
       "  19: '09:54:00',\n",
       "  20: '09:55:00',\n",
       "  21: '09:56:00',\n",
       "  22: '09:57:00',\n",
       "  23: '09:58:00',\n",
       "  24: '09:59:00',\n",
       "  25: '10:00:00',\n",
       "  26: '10:01:00',\n",
       "  27: '10:02:00',\n",
       "  28: '10:03:00',\n",
       "  29: '10:04:00',\n",
       "  30: '10:05:00',\n",
       "  31: '10:06:00',\n",
       "  32: '10:07:00',\n",
       "  33: '10:08:00',\n",
       "  34: '10:09:00',\n",
       "  35: '10:10:00',\n",
       "  36: '10:11:00',\n",
       "  37: '10:12:00',\n",
       "  38: '10:13:00',\n",
       "  39: '10:14:00',\n",
       "  40: '10:15:00',\n",
       "  41: '10:16:00',\n",
       "  42: '10:17:00',\n",
       "  43: '10:18:00',\n",
       "  44: '10:19:00',\n",
       "  45: '10:20:00',\n",
       "  46: '10:21:00',\n",
       "  47: '10:22:00',\n",
       "  48: '10:23:00',\n",
       "  49: '10:24:00'},\n",
       " 'day': {0: datetime.date(2010, 1, 4),\n",
       "  1: datetime.date(2010, 1, 4),\n",
       "  2: datetime.date(2010, 1, 4),\n",
       "  3: datetime.date(2010, 1, 4),\n",
       "  4: datetime.date(2010, 1, 4),\n",
       "  5: datetime.date(2010, 1, 4),\n",
       "  6: datetime.date(2010, 1, 4),\n",
       "  7: datetime.date(2010, 1, 4),\n",
       "  8: datetime.date(2010, 1, 4),\n",
       "  9: datetime.date(2010, 1, 4),\n",
       "  10: datetime.date(2010, 1, 4),\n",
       "  11: datetime.date(2010, 1, 4),\n",
       "  12: datetime.date(2010, 1, 4),\n",
       "  13: datetime.date(2010, 1, 4),\n",
       "  14: datetime.date(2010, 1, 4),\n",
       "  15: datetime.date(2010, 1, 4),\n",
       "  16: datetime.date(2010, 1, 4),\n",
       "  17: datetime.date(2010, 1, 4),\n",
       "  18: datetime.date(2010, 1, 4),\n",
       "  19: datetime.date(2010, 1, 4),\n",
       "  20: datetime.date(2010, 1, 4),\n",
       "  21: datetime.date(2010, 1, 4),\n",
       "  22: datetime.date(2010, 1, 4),\n",
       "  23: datetime.date(2010, 1, 4),\n",
       "  24: datetime.date(2010, 1, 4),\n",
       "  25: datetime.date(2010, 1, 4),\n",
       "  26: datetime.date(2010, 1, 4),\n",
       "  27: datetime.date(2010, 1, 4),\n",
       "  28: datetime.date(2010, 1, 4),\n",
       "  29: datetime.date(2010, 1, 4),\n",
       "  30: datetime.date(2010, 1, 4),\n",
       "  31: datetime.date(2010, 1, 4),\n",
       "  32: datetime.date(2010, 1, 4),\n",
       "  33: datetime.date(2010, 1, 4),\n",
       "  34: datetime.date(2010, 1, 4),\n",
       "  35: datetime.date(2010, 1, 4),\n",
       "  36: datetime.date(2010, 1, 4),\n",
       "  37: datetime.date(2010, 1, 4),\n",
       "  38: datetime.date(2010, 1, 4),\n",
       "  39: datetime.date(2010, 1, 4),\n",
       "  40: datetime.date(2010, 1, 4),\n",
       "  41: datetime.date(2010, 1, 4),\n",
       "  42: datetime.date(2010, 1, 4),\n",
       "  43: datetime.date(2010, 1, 4),\n",
       "  44: datetime.date(2010, 1, 4),\n",
       "  45: datetime.date(2010, 1, 4),\n",
       "  46: datetime.date(2010, 1, 4),\n",
       "  47: datetime.date(2010, 1, 4),\n",
       "  48: datetime.date(2010, 1, 4),\n",
       "  49: datetime.date(2010, 1, 4)}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_first3.head(50).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1f27dbea-570c-494c-b1e1-347046ac6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_stock(df_raw, patch_len, train_frac, val_frac):\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # turn column to datetime, add helper day column\n",
    "    df[\"Date Time\"] = pd.to_datetime(df[\"Date Time\"])\n",
    "    df = df.sort_values(\"Date Time\")\n",
    "    df[\"day\"] = df[\"Date Time\"].dt.date\n",
    "\n",
    "    # minutely log returns withing days from close\n",
    "    # fill first minute with 0 returns\n",
    "    df[\"log_close\"] = np.log(df[\"Close\"].astype(float))\n",
    "    df[\"ret_1m\"] = df.groupby(\"day\")[\"log_close\"].diff().fillna(0.0)\n",
    "\n",
    "    # to check if each days actually has 381 return minutes\n",
    "    day_return_count = df.groupby(\"day\")[\"ret_1m\"].size()\n",
    "    print(day_return_count.value_counts())\n",
    "    bars_mode = int(day_return_count.mode().iat[0]) # get mode of return minutes across dataset\n",
    "\n",
    "    # compute daily RV\n",
    "    daily = (df.groupby(\"day\")[\"ret_1m\"]\n",
    "               .agg(rv=lambda x: np.sum(x**2))\n",
    "               .reset_index())\n",
    "    \n",
    "    # in case there is a zero RV, replace it with small value before log\n",
    "    daily[\"log_rv\"] = np.log(daily[\"rv\"].replace(0.0, 1e-12))\n",
    "    # label for inputs from day d is log_rv of day d+1\n",
    "    daily[\"log_rv_tplus1\"] = daily[\"log_rv\"].shift(-1)\n",
    "    \n",
    "    # create binary filter for days without valid target (prob just last day)\n",
    "    valid_days = daily.dropna(subset=[\"log_rv_tplus1\"])[\"day\"]\n",
    "    # remove them from both minute_df and daily_df\n",
    "    df = df[df[\"day\"].isin(valid_days)].copy()\n",
    "    daily = daily[daily[\"day\"].isin(valid_days)].reset_index(drop=True)\n",
    "\n",
    "    # create minute index in each day\n",
    "    df[\"idx_in_day\"] = df.groupby(\"day\").cumcount()\n",
    "\n",
    "    # flag if we want to patch\n",
    "    if patch_len == 1:\n",
    "        # No patching: 1-minute tokens\n",
    "        df[\"patch_id\"] = df[\"idx_in_day\"]\n",
    "    # patch index inside day\n",
    "    else:\n",
    "        df[\"patch_id\"] = (df[\"idx_in_day\"] // patch_len).astype(int)\n",
    "\n",
    "    # number of full patches per day (patches with len() == patch_len)\n",
    "    tokens_full = (bars_mode // patch_len) if patch_len > 1 else bars_mode\n",
    "\n",
    "     # collect aggregate information for each patch\n",
    "    g = df.groupby([\"day\", \"patch_id\"])\n",
    "    patch = g.agg(\n",
    "        r_sum=(\"ret_1m\", \"sum\"), # summed returns\n",
    "        r_abs=(\"ret_1m\", lambda x: np.abs(x).sum()), # summed absolute returns\n",
    "        r_sq =(\"ret_1m\", lambda x: np.sum(x**2)), # summed squared returns\n",
    "        hi   =(\"High\", \"max\"), # high\n",
    "        lo   =(\"Low\", \"min\"), # low\n",
    "        vol  =(\"Volume\", \"sum\"), # volumne\n",
    "        r_last=(\"ret_1m\", \"last\"), # last return\n",
    "        n    =(\"ret_1m\", \"size\"), # number of values (should be patch_len)\n",
    "    ).reset_index()\n",
    "\n",
    "    # drop the last not filled token\n",
    "    patch = patch[patch[\"patch_id\"] < tokens_full].copy()\n",
    "\n",
    "    # robust log range\n",
    "    # patch[\"range_hl\"] = np.log(patch[\"hi\"] / patch[\"lo\"].replace(0, np.nan)).replace([np.inf, -np.inf], 0.0).fillna(0.0)\n",
    "    # patch = patch.drop(columns=[\"hi\", \"lo\"])\n",
    "\n",
    "\n",
    "\n",
    "    # positional encoding\n",
    "    \n",
    "    # relative time-of-day encoding\n",
    "    if tokens_full > 1:\n",
    "        patch[\"pos\"] = patch[\"patch_id\"] / (tokens_full - 1)\n",
    "    else:\n",
    "        patch[\"pos\"] = 0.0\n",
    "    patch[\"pos_sin\"] = np.sin(2 * np.pi * patch[\"pos\"])\n",
    "    patch[\"pos_cos\"] = np.cos(2 * np.pi * patch[\"pos\"])\n",
    "\n",
    "    # calendar encoding\n",
    "    # create small calendar daily index\n",
    "    cal = patch[[\"day\"]].drop_duplicates().copy()\n",
    "    cal_dt = pd.to_datetime(cal[\"day\"])\n",
    "    \n",
    "    # Day of Week\n",
    "    dow = cal_dt.dt.weekday\n",
    "    cal[\"dow_sin\"] = np.sin(2 * np.pi * dow / 7.0)\n",
    "    cal[\"dow_cos\"] = np.cos(2 * np.pi * dow / 7.0)\n",
    "    \n",
    "    # Day of Month\n",
    "    dom = cal_dt.dt.day\n",
    "    cal[\"dom_sin\"] = np.sin(2 * np.pi * dom / 31.0)\n",
    "    cal[\"dom_cos\"] = np.cos(2 * np.pi * dom / 31.0)\n",
    "    \n",
    "    # Month of Year\n",
    "    moy = cal_dt.dt.month\n",
    "    cal[\"moy_sin\"] = np.sin(2 * np.pi * moy / 12.0)\n",
    "    cal[\"moy_cos\"] = np.cos(2 * np.pi * moy / 12.0)\n",
    "\n",
    "    # Month-end flag (useful for rebalancing effects)\n",
    "    cal[\"is_month_end\"] = cal_dt.dt.is_month_end.astype(np.int8)\n",
    "\n",
    "    # Attach calendar features to every patch in that day\n",
    "    patch = patch.merge(cal, on=\"day\", how=\"left\")\n",
    "\n",
    "    feat_cols = [\n",
    "        \"r_sum\", \"r_abs\", \"r_sq\", \"vol\", \"r_last\",     # patch stats\n",
    "        \"pos_sin\", \"pos_cos\",                                      # time-of-day\n",
    "        \"dow_sin\", \"dow_cos\", \"dom_sin\", \"dom_cos\", \"moy_sin\", \"moy_cos\",  # calendar\n",
    "        \"is_month_end\",                                            # flag (0/1)\n",
    "    ]\n",
    "\n",
    "\n",
    "    # ------------ BUILD X\n",
    "    # get unique trading days, patch has one row for each patch\n",
    "    day_list = sorted(patch[\"day\"].unique())\n",
    "    # initialize lists\n",
    "    X_days, y_days = [], []\n",
    "    # map each day to its target in a dict\n",
    "    label_map = dict(zip(daily[\"day\"], daily[\"log_rv_tplus1\"]))\n",
    "\n",
    "    # loop over trading days\n",
    "    for d in day_list:\n",
    "        # get all patches in one day sorted by time\n",
    "        day_p = patch[(patch[\"day\"] == d)].sort_values(\"patch_id\")\n",
    "        # skip days with not full patches\n",
    "        if day_p.shape[0] != tokens_full:\n",
    "            continue\n",
    "        # turn features into numpy array of [Patch_len, n_features]\n",
    "        # each Xi is a matrix representation of one trading day\n",
    "        Xi = day_p[feat_cols].to_numpy(dtype=np.float32)            # [T_patches, d_features]\n",
    "        # look up target for that day from dict\n",
    "        yi = float(label_map[d])                                    # scalar target (log RV)\n",
    "        X_days.append(Xi)\n",
    "        y_days.append(yi)\n",
    "\n",
    "    # stack data\n",
    "    X = np.stack(X_days, axis=0)            # [N_days, T_tokens, d_in]\n",
    "    y = np.array(y_days, dtype=np.float32)  # [N_days]\n",
    "\n",
    "\n",
    "\n",
    "    # ------------- Train - Val - Test - Split\n",
    "    # number of trading days in data set\n",
    "    N = X.shape[0]\n",
    "    # train split\n",
    "    n_tr = int(N * train_frac)\n",
    "    # val split\n",
    "    n_va = int(N * val_frac)\n",
    "\n",
    "    # comput split indices\n",
    "    idx_tr = slice(0, n_tr)\n",
    "    idx_va = slice(n_tr, n_tr + n_va)\n",
    "    idx_te = slice(n_tr + n_va, N)\n",
    "\n",
    "    # split data\n",
    "    X_train, y_train = X[idx_tr], y[idx_tr]\n",
    "    X_val, y_val = X[idx_va], y[idx_va]\n",
    "    X_test, y_test = X[idx_te], y[idx_te]\n",
    "\n",
    "    # ------------------- Scaling\n",
    "\n",
    "    # only use train data for mean and sd\n",
    "    # flattens across days and tokens\n",
    "    mu = X_train.reshape(-1, X_train.shape[-1]).mean(axis=0, keepdims=True)   # [1, d_in], mean of each feature\n",
    "    sd = X_train.reshape(-1, X_train.shape[-1]).std(axis=0, keepdims=True) + 1e-8 # sd of each feature\n",
    "\n",
    "    def scale(arr):\n",
    "        return (arr - mu) / sd\n",
    "\n",
    "    X_train = scale(X_train)\n",
    "    X_val = scale(X_val)\n",
    "    X_test = scale(X_test)\n",
    "    \n",
    "    return {\n",
    "        \"X_train\": X_train, \"y_train\": y_train,\n",
    "        \"X_val\":   X_val, \"y_val\":   y_val,\n",
    "        \"X_test\":  X_test, \"y_test\":  y_test,\n",
    "        \"meta\": {\n",
    "            \"tokens_per_day\": tokens_full,\n",
    "            \"feature_names\": feat_cols,\n",
    "            \"bars_per_day_mode\": bars_mode,\n",
    "            \"train_days\": int(n_tr),\n",
    "            \"val_days\": int(n_va),\n",
    "            \"test_days\": int(N - n_tr - n_va),\n",
    "            \"scaler_mean\": mu.astype(np.float32),\n",
    "            \"scaler_std\": sd.astype(np.float32),\n",
    "            \"patch_len_minutes\": patch_len,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0c855295-0298-479c-bcec-88c74f3e320a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret_1m\n",
      "381    2516\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = preprocess_stock(IBM, 20, 0.7, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "79bded92-39ce-40c1-8af3-28e1e494bdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04 09:35:00</td>\n",
       "      <td>85.2401</td>\n",
       "      <td>85.2789</td>\n",
       "      <td>85.1624</td>\n",
       "      <td>85.2207</td>\n",
       "      <td>42796.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>09:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04 09:36:00</td>\n",
       "      <td>85.2271</td>\n",
       "      <td>85.4732</td>\n",
       "      <td>85.2142</td>\n",
       "      <td>85.4343</td>\n",
       "      <td>65921.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>09:36:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04 09:37:00</td>\n",
       "      <td>85.4214</td>\n",
       "      <td>85.4732</td>\n",
       "      <td>85.3048</td>\n",
       "      <td>85.4680</td>\n",
       "      <td>60876.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>09:37:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04 09:38:00</td>\n",
       "      <td>85.4732</td>\n",
       "      <td>85.5250</td>\n",
       "      <td>85.4279</td>\n",
       "      <td>85.5056</td>\n",
       "      <td>36812.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>09:38:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04 09:39:00</td>\n",
       "      <td>85.4946</td>\n",
       "      <td>85.5056</td>\n",
       "      <td>85.4214</td>\n",
       "      <td>85.4538</td>\n",
       "      <td>29232.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>09:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958591</th>\n",
       "      <td>2019-12-31 15:51:00</td>\n",
       "      <td>114.7837</td>\n",
       "      <td>114.8095</td>\n",
       "      <td>114.7794</td>\n",
       "      <td>114.8095</td>\n",
       "      <td>20723.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>15:51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958592</th>\n",
       "      <td>2019-12-31 15:52:00</td>\n",
       "      <td>114.8095</td>\n",
       "      <td>114.8438</td>\n",
       "      <td>114.8052</td>\n",
       "      <td>114.8438</td>\n",
       "      <td>24968.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>15:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958593</th>\n",
       "      <td>2019-12-31 15:53:00</td>\n",
       "      <td>114.8524</td>\n",
       "      <td>114.9038</td>\n",
       "      <td>114.8524</td>\n",
       "      <td>114.9038</td>\n",
       "      <td>39332.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>15:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958594</th>\n",
       "      <td>2019-12-31 15:54:00</td>\n",
       "      <td>114.9038</td>\n",
       "      <td>114.9296</td>\n",
       "      <td>114.8910</td>\n",
       "      <td>114.9038</td>\n",
       "      <td>20436.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>15:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958595</th>\n",
       "      <td>2019-12-31 15:55:00</td>\n",
       "      <td>114.9038</td>\n",
       "      <td>114.9553</td>\n",
       "      <td>114.8995</td>\n",
       "      <td>114.9467</td>\n",
       "      <td>30605.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>15:55:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>958596 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date Time      Open      High       Low     Close   Volume  \\\n",
       "0      2010-01-04 09:35:00   85.2401   85.2789   85.1624   85.2207  42796.0   \n",
       "1      2010-01-04 09:36:00   85.2271   85.4732   85.2142   85.4343  65921.0   \n",
       "2      2010-01-04 09:37:00   85.4214   85.4732   85.3048   85.4680  60876.0   \n",
       "3      2010-01-04 09:38:00   85.4732   85.5250   85.4279   85.5056  36812.0   \n",
       "4      2010-01-04 09:39:00   85.4946   85.5056   85.4214   85.4538  29232.0   \n",
       "...                    ...       ...       ...       ...       ...      ...   \n",
       "958591 2019-12-31 15:51:00  114.7837  114.8095  114.7794  114.8095  20723.0   \n",
       "958592 2019-12-31 15:52:00  114.8095  114.8438  114.8052  114.8438  24968.0   \n",
       "958593 2019-12-31 15:53:00  114.8524  114.9038  114.8524  114.9038  39332.0   \n",
       "958594 2019-12-31 15:54:00  114.9038  114.9296  114.8910  114.9038  20436.0   \n",
       "958595 2019-12-31 15:55:00  114.9038  114.9553  114.8995  114.9467  30605.0   \n",
       "\n",
       "              Date      Time  \n",
       "0       2010-01-04  09:35:00  \n",
       "1       2010-01-04  09:36:00  \n",
       "2       2010-01-04  09:37:00  \n",
       "3       2010-01-04  09:38:00  \n",
       "4       2010-01-04  09:39:00  \n",
       "...            ...       ...  \n",
       "958591  2019-12-31  15:51:00  \n",
       "958592  2019-12-31  15:52:00  \n",
       "958593  2019-12-31  15:53:00  \n",
       "958594  2019-12-31  15:54:00  \n",
       "958595  2019-12-31  15:55:00  \n",
       "\n",
       "[958596 rows x 8 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "95e36b4f-4eaa-4b59-b246-d013909745a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>day</th>\n",
       "      <th>log_close</th>\n",
       "      <th>ret_1m</th>\n",
       "      <th>idx_in_day</th>\n",
       "      <th>patch_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2010-01-04 15:51:00</td>\n",
       "      <td>85.7905</td>\n",
       "      <td>85.8034</td>\n",
       "      <td>85.7710</td>\n",
       "      <td>85.7905</td>\n",
       "      <td>18650.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>15:51:00</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>4.451908</td>\n",
       "      <td>-0.000150</td>\n",
       "      <td>376</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>2010-01-04 15:52:00</td>\n",
       "      <td>85.7905</td>\n",
       "      <td>85.8034</td>\n",
       "      <td>85.7710</td>\n",
       "      <td>85.7775</td>\n",
       "      <td>19197.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>15:52:00</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>4.451757</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>377</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>2010-01-04 15:53:00</td>\n",
       "      <td>85.7840</td>\n",
       "      <td>85.8099</td>\n",
       "      <td>85.7775</td>\n",
       "      <td>85.7970</td>\n",
       "      <td>19559.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>15:53:00</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>4.451984</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>378</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>2010-01-04 15:54:00</td>\n",
       "      <td>85.8099</td>\n",
       "      <td>85.8229</td>\n",
       "      <td>85.7970</td>\n",
       "      <td>85.8047</td>\n",
       "      <td>26483.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>15:54:00</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>4.452074</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>379</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>2010-01-04 15:55:00</td>\n",
       "      <td>85.8099</td>\n",
       "      <td>85.8358</td>\n",
       "      <td>85.7970</td>\n",
       "      <td>85.8229</td>\n",
       "      <td>39052.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>15:55:00</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>4.452286</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>380</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>2010-01-05 09:35:00</td>\n",
       "      <td>84.6767</td>\n",
       "      <td>84.8516</td>\n",
       "      <td>84.6767</td>\n",
       "      <td>84.7415</td>\n",
       "      <td>123004.0</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>09:35:00</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>4.439605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>2010-01-05 09:36:00</td>\n",
       "      <td>84.7415</td>\n",
       "      <td>84.7544</td>\n",
       "      <td>84.6638</td>\n",
       "      <td>84.7318</td>\n",
       "      <td>101782.0</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>09:36:00</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>4.439491</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2010-01-05 09:37:00</td>\n",
       "      <td>84.7415</td>\n",
       "      <td>84.7933</td>\n",
       "      <td>84.7221</td>\n",
       "      <td>84.7577</td>\n",
       "      <td>30386.0</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>09:37:00</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>4.439797</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2010-01-05 09:38:00</td>\n",
       "      <td>84.7544</td>\n",
       "      <td>84.7609</td>\n",
       "      <td>84.7091</td>\n",
       "      <td>84.7285</td>\n",
       "      <td>45357.0</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>09:38:00</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>4.439452</td>\n",
       "      <td>-0.000345</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2010-01-05 09:39:00</td>\n",
       "      <td>84.7285</td>\n",
       "      <td>84.7285</td>\n",
       "      <td>84.6832</td>\n",
       "      <td>84.7026</td>\n",
       "      <td>37723.0</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>09:39:00</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>4.439146</td>\n",
       "      <td>-0.000306</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2010-01-05 09:40:00</td>\n",
       "      <td>84.7026</td>\n",
       "      <td>84.7026</td>\n",
       "      <td>84.5537</td>\n",
       "      <td>84.5926</td>\n",
       "      <td>67619.0</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>09:40:00</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>4.437847</td>\n",
       "      <td>-0.001300</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2010-01-05 09:41:00</td>\n",
       "      <td>84.5667</td>\n",
       "      <td>84.6055</td>\n",
       "      <td>84.5537</td>\n",
       "      <td>84.5537</td>\n",
       "      <td>28418.0</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>09:41:00</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>4.437387</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2010-01-05 09:42:00</td>\n",
       "      <td>84.5602</td>\n",
       "      <td>84.6638</td>\n",
       "      <td>84.5537</td>\n",
       "      <td>84.6379</td>\n",
       "      <td>69582.0</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>09:42:00</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>4.438382</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2010-01-05 09:43:00</td>\n",
       "      <td>84.6476</td>\n",
       "      <td>84.7091</td>\n",
       "      <td>84.5796</td>\n",
       "      <td>84.7039</td>\n",
       "      <td>43221.0</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>09:43:00</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>4.439162</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date Time     Open     High      Low    Close    Volume  \\\n",
       "376 2010-01-04 15:51:00  85.7905  85.8034  85.7710  85.7905   18650.0   \n",
       "377 2010-01-04 15:52:00  85.7905  85.8034  85.7710  85.7775   19197.0   \n",
       "378 2010-01-04 15:53:00  85.7840  85.8099  85.7775  85.7970   19559.0   \n",
       "379 2010-01-04 15:54:00  85.8099  85.8229  85.7970  85.8047   26483.0   \n",
       "380 2010-01-04 15:55:00  85.8099  85.8358  85.7970  85.8229   39052.0   \n",
       "381 2010-01-05 09:35:00  84.6767  84.8516  84.6767  84.7415  123004.0   \n",
       "382 2010-01-05 09:36:00  84.7415  84.7544  84.6638  84.7318  101782.0   \n",
       "383 2010-01-05 09:37:00  84.7415  84.7933  84.7221  84.7577   30386.0   \n",
       "384 2010-01-05 09:38:00  84.7544  84.7609  84.7091  84.7285   45357.0   \n",
       "385 2010-01-05 09:39:00  84.7285  84.7285  84.6832  84.7026   37723.0   \n",
       "386 2010-01-05 09:40:00  84.7026  84.7026  84.5537  84.5926   67619.0   \n",
       "387 2010-01-05 09:41:00  84.5667  84.6055  84.5537  84.5537   28418.0   \n",
       "388 2010-01-05 09:42:00  84.5602  84.6638  84.5537  84.6379   69582.0   \n",
       "389 2010-01-05 09:43:00  84.6476  84.7091  84.5796  84.7039   43221.0   \n",
       "\n",
       "           Date      Time         day  log_close    ret_1m  idx_in_day  \\\n",
       "376  2010-01-04  15:51:00  2010-01-04   4.451908 -0.000150         376   \n",
       "377  2010-01-04  15:52:00  2010-01-04   4.451757 -0.000152         377   \n",
       "378  2010-01-04  15:53:00  2010-01-04   4.451984  0.000227         378   \n",
       "379  2010-01-04  15:54:00  2010-01-04   4.452074  0.000090         379   \n",
       "380  2010-01-04  15:55:00  2010-01-04   4.452286  0.000212         380   \n",
       "381  2010-01-05  09:35:00  2010-01-05   4.439605  0.000000           0   \n",
       "382  2010-01-05  09:36:00  2010-01-05   4.439491 -0.000114           1   \n",
       "383  2010-01-05  09:37:00  2010-01-05   4.439797  0.000306           2   \n",
       "384  2010-01-05  09:38:00  2010-01-05   4.439452 -0.000345           3   \n",
       "385  2010-01-05  09:39:00  2010-01-05   4.439146 -0.000306           4   \n",
       "386  2010-01-05  09:40:00  2010-01-05   4.437847 -0.001300           5   \n",
       "387  2010-01-05  09:41:00  2010-01-05   4.437387 -0.000460           6   \n",
       "388  2010-01-05  09:42:00  2010-01-05   4.438382  0.000995           7   \n",
       "389  2010-01-05  09:43:00  2010-01-05   4.439162  0.000779           8   \n",
       "\n",
       "     patch_id  \n",
       "376        18  \n",
       "377        18  \n",
       "378        18  \n",
       "379        18  \n",
       "380        19  \n",
       "381         0  \n",
       "382         0  \n",
       "383         0  \n",
       "384         0  \n",
       "385         0  \n",
       "386         0  \n",
       "387         0  \n",
       "388         0  \n",
       "389         0  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.iloc[376:390]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "781cf938-f776-469e-b3db-a5f2351deefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret_1m\n",
      "381    2516\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def stack_context_days(X_days, y_days, context_window=22):\n",
    "    N, T, d = X_days.shape # n_trading_days, tokens_per_day, features_per_token\n",
    "\n",
    "    # initialize stack lists\n",
    "    Xc, yc = [], []\n",
    "\n",
    "    # slide rollwing window over dataset\n",
    "    for i in range(N - context_window + 1):\n",
    "        Xi = X_days[i:i+context_window].reshape(context_window * T, d)  # [seq_len, d]\n",
    "        yi = y_days[i + context_window - 1]  # label aligned to last input day → predict next day\n",
    "\n",
    "        # append sequence and length to lists\n",
    "        Xc.append(Xi)\n",
    "        yc.append(yi)\n",
    "\n",
    "    # return stacked sequences\n",
    "    return np.stack(Xc).astype(np.float32), np.array(yc, dtype=np.float32)\n",
    "\n",
    "out = preprocess_stock(df_ibm, patch_len=15, train_frac=0.7, val_frac=0.15)\n",
    "Xtr_ctx, ytr_ctx = stack_context_days(out[\"X_train\"], out[\"y_train\"], context_window=22)\n",
    "Xva_ctx, yva_ctx = stack_context_days(out[\"X_val\"],   out[\"y_val\"],   context_window=22)\n",
    "Xte_ctx, yte_ctx = stack_context_days(out[\"X_test\"],  out[\"y_test\"],  context_window=22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "cea43699-c3f9-4bea-9fdf-65038a33c19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1760, 25, 14)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"X_train\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "096881c7-44ce-4b1d-8922-718c5796b969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1739, 550, 14)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr_ctx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "98173789-6686-4e9d-8ee9-f729eed90d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First seq shape: (550, 14)\n",
      "First target: -8.786377\n"
     ]
    }
   ],
   "source": [
    "first_seq = Xtr_ctx[0]        # [seq_len, d]\n",
    "first_target = ytr_ctx[0]     # scalar\n",
    "\n",
    "print(\"First seq shape:\", first_seq.shape)\n",
    "print(\"First target:\", first_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dc46e7-7b91-440f-8ca4-d346f6b7a4f6",
   "metadata": {},
   "source": [
    "# ARCHIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de88bde8-1bb5-4141-a290-de45a4a1a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "def preprocess_one_stock(\n",
    "    df_raw: pd.DataFrame,\n",
    "    patch_len: int = 15,           # minutes per token; set to 1 to skip patching\n",
    "    train_frac: float = 0.7,\n",
    "    val_frac: float = 0.15,\n",
    "    clip_return: float = None,     # winsorize per-minute returns to ±5%\n",
    "    drop_half_days: bool = True,   # drop days not matching the modal intraday length\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Preprocess a single-stock minute dataframe into per-day token sequences and next-day log-RV labels.\n",
    "\n",
    "    Input df_raw columns (as in your printout):\n",
    "      [\"Date Time\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\",\"Date\",\"Time\"]\n",
    "\n",
    "    Returns:\n",
    "      dict with X_train, y_train, X_val, y_val, X_test, y_test, plus meta.\n",
    "      Shapes: X_* = [N_days, T_tokens, d_in], y_* = [N_days]\n",
    "    \"\"\"\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # ---- 1) Parse & sort time; derive calendar day ----\n",
    "    df[\"Date Time\"] = pd.to_datetime(df[\"Date Time\"], errors=\"coerce\")\n",
    "    #df = df.dropna(subset=[\"Date Time\"]).sort_values(\"Date Time\").reset_index(drop=True)\n",
    "    df = df.sort_values(\"Date Time\").reset_index(drop=True)\n",
    "    df[\"day\"] = df[\"Date Time\"].dt.date\n",
    "\n",
    "\n",
    "    if clip_return is not None:\n",
    "        df[\"ret_1m\"] = df[\"ret_1m\"].clip(-clip_return, clip_return)\n",
    "\n",
    "    # ---- 3) Bars per day & optional half-day removal ----\n",
    "    \n",
    "\n",
    "    # ---- 4) Day-level realized variance and next-day label ----\n",
    "    daily = (df.groupby(\"day\")[\"ret_1m\"]\n",
    "               .agg(rv=lambda x: np.sum(x**2))\n",
    "               .reset_index())\n",
    "    daily[\"log_rv\"] = np.log(daily[\"rv\"].replace(0.0, 1e-12))\n",
    "    # label for inputs from day d is log_rv of day d+1\n",
    "    daily[\"log_rv_tplus1\"] = daily[\"log_rv\"].shift(-1)\n",
    "\n",
    "    # Keep only days that have a next-day label\n",
    "    valid_days = daily.dropna(subset=[\"log_rv_tplus1\"])[\"day\"]\n",
    "    df = df[df[\"day\"].isin(valid_days)].copy()\n",
    "    daily = daily[daily[\"day\"].isin(valid_days)].reset_index(drop=True)\n",
    "\n",
    "    # ---- 5) Build per-day tokens (patching) ----\n",
    "    # index within day and patch id\n",
    "    df[\"idx_in_day\"] = df.groupby(\"day\").cumcount()\n",
    "    if patch_len <= 1:\n",
    "        # No patching: 1-minute tokens\n",
    "        df[\"patch_id\"] = df[\"idx_in_day\"]\n",
    "    else:\n",
    "        df[\"patch_id\"] = (df[\"idx_in_day\"] // patch_len).astype(int)\n",
    "\n",
    "    # number of *full* tokens per typical day (drop last partial patch for stability)\n",
    "    tokens_full = (bars_mode // patch_len) if patch_len > 1 else bars_mode\n",
    "\n",
    "    # aggregate per (day, patch_id)\n",
    "    g = df.groupby([\"day\", \"patch_id\"])\n",
    "    patch = g.agg(\n",
    "        r_sum=(\"ret_1m\", \"sum\"),\n",
    "        r_abs=(\"ret_1m\", lambda x: np.abs(x).sum()),\n",
    "        r_sq =(\"ret_1m\", lambda x: np.sum(x**2)),\n",
    "        hi   =(\"High\", \"max\"),\n",
    "        lo   =(\"Low\", \"min\"),\n",
    "        vol  =(\"Volume\", \"sum\"),\n",
    "        r_last=(\"ret_1m\", \"last\"),\n",
    "        n    =(\"ret_1m\", \"size\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    # keep only the first 'tokens_full' patches per day (drop partial tail)\n",
    "    patch = patch[patch[\"patch_id\"] < tokens_full].copy()\n",
    "\n",
    "    # robust log range\n",
    "    patch[\"range_hl\"] = np.log(patch[\"hi\"] / patch[\"lo\"].replace(0, np.nan)).replace([np.inf, -np.inf], 0.0).fillna(0.0)\n",
    "    patch = patch.drop(columns=[\"hi\", \"lo\"])\n",
    "\n",
    "    # time-of-day encodings\n",
    "    if tokens_full > 1:\n",
    "        patch[\"pos\"] = patch[\"patch_id\"] / (tokens_full - 1)\n",
    "    else:\n",
    "        patch[\"pos\"] = 0.0\n",
    "    patch[\"pos_sin\"] = np.sin(2 * np.pi * patch[\"pos\"])\n",
    "    patch[\"pos_cos\"] = np.cos(2 * np.pi * patch[\"pos\"])\n",
    "\n",
    "    feat_cols = [\"r_sum\", \"r_abs\", \"r_sq\", \"range_hl\", \"vol\", \"r_last\", \"pos_sin\", \"pos_cos\"]\n",
    "\n",
    "    # ---- 6) Build X (per-day tokens × features) and y (next-day log-RV) ----\n",
    "    day_list = sorted(patch[\"day\"].unique())\n",
    "    X_days, y_days = [], []\n",
    "    label_map = dict(zip(daily[\"day\"], daily[\"log_rv_tplus1\"]))\n",
    "\n",
    "    for d in day_list:\n",
    "        day_p = patch[(patch[\"day\"] == d)].sort_values(\"patch_id\")\n",
    "        # ensure we have exactly tokens_full tokens\n",
    "        if day_p.shape[0] != tokens_full:\n",
    "            continue\n",
    "        Xi = day_p[feat_cols].to_numpy(dtype=np.float32)            # [T_tokens, d_in]\n",
    "        yi = float(label_map[d])                                    # scalar target\n",
    "        X_days.append(Xi)\n",
    "        y_days.append(yi)\n",
    "\n",
    "    X = np.stack(X_days, axis=0)            # [N_days, T_tokens, d_in]\n",
    "    y = np.array(y_days, dtype=np.float32)  # [N_days]\n",
    "\n",
    "    # ---- 7) Temporal split (by day order) ----\n",
    "    N = X.shape[0]\n",
    "    n_tr = int(N * train_frac)\n",
    "    n_va = int(N * val_frac)\n",
    "    idx_tr = slice(0, n_tr)\n",
    "    idx_va = slice(n_tr, n_tr + n_va)\n",
    "    idx_te = slice(n_tr + n_va, N)\n",
    "\n",
    "    X_tr, y_tr = X[idx_tr], y[idx_tr]\n",
    "    X_va, y_va = X[idx_va], y[idx_va]\n",
    "    X_te, y_te = X[idx_te], y[idx_te]\n",
    "\n",
    "    # ---- 8) Feature scaling with train stats only ----\n",
    "    mu = X_tr.reshape(-1, X_tr.shape[-1]).mean(axis=0, keepdims=True)   # [1, d_in]\n",
    "    sd = X_tr.reshape(-1, X_tr.shape[-1]).std(axis=0, keepdims=True) + 1e-8\n",
    "\n",
    "    def scale(arr):\n",
    "        return (arr - mu) / sd\n",
    "\n",
    "    X_tr = scale(X_tr); X_va = scale(X_va); X_te = scale(X_te)\n",
    "\n",
    "    return {\n",
    "        \"X_train\": X_tr, \"y_train\": y_tr,\n",
    "        \"X_val\":   X_va, \"y_val\":   y_va,\n",
    "        \"X_test\":  X_te, \"y_test\":  y_te,\n",
    "        \"meta\": {\n",
    "            \"tokens_per_day\": tokens_full,\n",
    "            \"feature_names\": feat_cols,\n",
    "            \"bars_per_day_mode\": bars_mode,\n",
    "            \"train_days\": int(n_tr),\n",
    "            \"val_days\": int(n_va),\n",
    "            \"test_days\": int(N - n_tr - n_va),\n",
    "            \"scaler_mean\": mu.astype(np.float32),\n",
    "            \"scaler_std\": sd.astype(np.float32),\n",
    "            \"patch_len_minutes\": patch_len,\n",
    "        },\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ae7b0d9-4dec-4cc3-9693-aa83f13815d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = IBM.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce72faf1-a84b-4002-a56a-e94b3e3d1fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date Time\"] = pd.to_datetime(df[\"Date Time\"], errors=\"coerce\")\n",
    "#df = df.dropna(subset=[\"Date Time\"]).sort_values(\"Date Time\").reset_index(drop=True)\n",
    "df = df.sort_values(\"Date Time\").reset_index(drop=True)\n",
    "df[\"day\"] = df[\"Date Time\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bbeba76a-788c-42e0-9d1d-6570d094fd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04 09:35:00</td>\n",
       "      <td>85.2401</td>\n",
       "      <td>85.2789</td>\n",
       "      <td>85.1624</td>\n",
       "      <td>85.2207</td>\n",
       "      <td>42796.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>09:35:00</td>\n",
       "      <td>2010-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04 09:36:00</td>\n",
       "      <td>85.2271</td>\n",
       "      <td>85.4732</td>\n",
       "      <td>85.2142</td>\n",
       "      <td>85.4343</td>\n",
       "      <td>65921.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>09:36:00</td>\n",
       "      <td>2010-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04 09:37:00</td>\n",
       "      <td>85.4214</td>\n",
       "      <td>85.4732</td>\n",
       "      <td>85.3048</td>\n",
       "      <td>85.4680</td>\n",
       "      <td>60876.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>09:37:00</td>\n",
       "      <td>2010-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04 09:38:00</td>\n",
       "      <td>85.4732</td>\n",
       "      <td>85.5250</td>\n",
       "      <td>85.4279</td>\n",
       "      <td>85.5056</td>\n",
       "      <td>36812.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>09:38:00</td>\n",
       "      <td>2010-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04 09:39:00</td>\n",
       "      <td>85.4946</td>\n",
       "      <td>85.5056</td>\n",
       "      <td>85.4214</td>\n",
       "      <td>85.4538</td>\n",
       "      <td>29232.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>09:39:00</td>\n",
       "      <td>2010-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958591</th>\n",
       "      <td>2019-12-31 15:51:00</td>\n",
       "      <td>114.7837</td>\n",
       "      <td>114.8095</td>\n",
       "      <td>114.7794</td>\n",
       "      <td>114.8095</td>\n",
       "      <td>20723.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>15:51:00</td>\n",
       "      <td>2019-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958592</th>\n",
       "      <td>2019-12-31 15:52:00</td>\n",
       "      <td>114.8095</td>\n",
       "      <td>114.8438</td>\n",
       "      <td>114.8052</td>\n",
       "      <td>114.8438</td>\n",
       "      <td>24968.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>15:52:00</td>\n",
       "      <td>2019-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958593</th>\n",
       "      <td>2019-12-31 15:53:00</td>\n",
       "      <td>114.8524</td>\n",
       "      <td>114.9038</td>\n",
       "      <td>114.8524</td>\n",
       "      <td>114.9038</td>\n",
       "      <td>39332.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>15:53:00</td>\n",
       "      <td>2019-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958594</th>\n",
       "      <td>2019-12-31 15:54:00</td>\n",
       "      <td>114.9038</td>\n",
       "      <td>114.9296</td>\n",
       "      <td>114.8910</td>\n",
       "      <td>114.9038</td>\n",
       "      <td>20436.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>15:54:00</td>\n",
       "      <td>2019-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958595</th>\n",
       "      <td>2019-12-31 15:55:00</td>\n",
       "      <td>114.9038</td>\n",
       "      <td>114.9553</td>\n",
       "      <td>114.8995</td>\n",
       "      <td>114.9467</td>\n",
       "      <td>30605.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>15:55:00</td>\n",
       "      <td>2019-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>958596 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date Time      Open      High       Low     Close   Volume  \\\n",
       "0      2010-01-04 09:35:00   85.2401   85.2789   85.1624   85.2207  42796.0   \n",
       "1      2010-01-04 09:36:00   85.2271   85.4732   85.2142   85.4343  65921.0   \n",
       "2      2010-01-04 09:37:00   85.4214   85.4732   85.3048   85.4680  60876.0   \n",
       "3      2010-01-04 09:38:00   85.4732   85.5250   85.4279   85.5056  36812.0   \n",
       "4      2010-01-04 09:39:00   85.4946   85.5056   85.4214   85.4538  29232.0   \n",
       "...                    ...       ...       ...       ...       ...      ...   \n",
       "958591 2019-12-31 15:51:00  114.7837  114.8095  114.7794  114.8095  20723.0   \n",
       "958592 2019-12-31 15:52:00  114.8095  114.8438  114.8052  114.8438  24968.0   \n",
       "958593 2019-12-31 15:53:00  114.8524  114.9038  114.8524  114.9038  39332.0   \n",
       "958594 2019-12-31 15:54:00  114.9038  114.9296  114.8910  114.9038  20436.0   \n",
       "958595 2019-12-31 15:55:00  114.9038  114.9553  114.8995  114.9467  30605.0   \n",
       "\n",
       "              Date      Time         day  \n",
       "0       2010-01-04  09:35:00  2010-01-04  \n",
       "1       2010-01-04  09:36:00  2010-01-04  \n",
       "2       2010-01-04  09:37:00  2010-01-04  \n",
       "3       2010-01-04  09:38:00  2010-01-04  \n",
       "4       2010-01-04  09:39:00  2010-01-04  \n",
       "...            ...       ...         ...  \n",
       "958591  2019-12-31  15:51:00  2019-12-31  \n",
       "958592  2019-12-31  15:52:00  2019-12-31  \n",
       "958593  2019-12-31  15:53:00  2019-12-31  \n",
       "958594  2019-12-31  15:54:00  2019-12-31  \n",
       "958595  2019-12-31  15:55:00  2019-12-31  \n",
       "\n",
       "[958596 rows x 9 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "edd80699-1392-4216-8219-4f608f6cbdd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04 09:35:00</td>\n",
       "      <td>85.2401</td>\n",
       "      <td>85.2789</td>\n",
       "      <td>85.1624</td>\n",
       "      <td>85.2207</td>\n",
       "      <td>42796.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>09:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04 09:36:00</td>\n",
       "      <td>85.2271</td>\n",
       "      <td>85.4732</td>\n",
       "      <td>85.2142</td>\n",
       "      <td>85.4343</td>\n",
       "      <td>65921.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>09:36:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04 09:37:00</td>\n",
       "      <td>85.4214</td>\n",
       "      <td>85.4732</td>\n",
       "      <td>85.3048</td>\n",
       "      <td>85.4680</td>\n",
       "      <td>60876.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>09:37:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04 09:38:00</td>\n",
       "      <td>85.4732</td>\n",
       "      <td>85.5250</td>\n",
       "      <td>85.4279</td>\n",
       "      <td>85.5056</td>\n",
       "      <td>36812.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>09:38:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04 09:39:00</td>\n",
       "      <td>85.4946</td>\n",
       "      <td>85.5056</td>\n",
       "      <td>85.4214</td>\n",
       "      <td>85.4538</td>\n",
       "      <td>29232.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>09:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958591</th>\n",
       "      <td>2019-12-31 15:51:00</td>\n",
       "      <td>114.7837</td>\n",
       "      <td>114.8095</td>\n",
       "      <td>114.7794</td>\n",
       "      <td>114.8095</td>\n",
       "      <td>20723.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>15:51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958592</th>\n",
       "      <td>2019-12-31 15:52:00</td>\n",
       "      <td>114.8095</td>\n",
       "      <td>114.8438</td>\n",
       "      <td>114.8052</td>\n",
       "      <td>114.8438</td>\n",
       "      <td>24968.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>15:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958593</th>\n",
       "      <td>2019-12-31 15:53:00</td>\n",
       "      <td>114.8524</td>\n",
       "      <td>114.9038</td>\n",
       "      <td>114.8524</td>\n",
       "      <td>114.9038</td>\n",
       "      <td>39332.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>15:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958594</th>\n",
       "      <td>2019-12-31 15:54:00</td>\n",
       "      <td>114.9038</td>\n",
       "      <td>114.9296</td>\n",
       "      <td>114.8910</td>\n",
       "      <td>114.9038</td>\n",
       "      <td>20436.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>15:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958595</th>\n",
       "      <td>2019-12-31 15:55:00</td>\n",
       "      <td>114.9038</td>\n",
       "      <td>114.9553</td>\n",
       "      <td>114.8995</td>\n",
       "      <td>114.9467</td>\n",
       "      <td>30605.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>15:55:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>958596 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date Time      Open      High       Low     Close   Volume  \\\n",
       "0      2010-01-04 09:35:00   85.2401   85.2789   85.1624   85.2207  42796.0   \n",
       "1      2010-01-04 09:36:00   85.2271   85.4732   85.2142   85.4343  65921.0   \n",
       "2      2010-01-04 09:37:00   85.4214   85.4732   85.3048   85.4680  60876.0   \n",
       "3      2010-01-04 09:38:00   85.4732   85.5250   85.4279   85.5056  36812.0   \n",
       "4      2010-01-04 09:39:00   85.4946   85.5056   85.4214   85.4538  29232.0   \n",
       "...                    ...       ...       ...       ...       ...      ...   \n",
       "958591 2019-12-31 15:51:00  114.7837  114.8095  114.7794  114.8095  20723.0   \n",
       "958592 2019-12-31 15:52:00  114.8095  114.8438  114.8052  114.8438  24968.0   \n",
       "958593 2019-12-31 15:53:00  114.8524  114.9038  114.8524  114.9038  39332.0   \n",
       "958594 2019-12-31 15:54:00  114.9038  114.9296  114.8910  114.9038  20436.0   \n",
       "958595 2019-12-31 15:55:00  114.9038  114.9553  114.8995  114.9467  30605.0   \n",
       "\n",
       "              Date      Time  \n",
       "0       2010-01-04  09:35:00  \n",
       "1       2010-01-04  09:36:00  \n",
       "2       2010-01-04  09:37:00  \n",
       "3       2010-01-04  09:38:00  \n",
       "4       2010-01-04  09:39:00  \n",
       "...            ...       ...  \n",
       "958591  2019-12-31  15:51:00  \n",
       "958592  2019-12-31  15:52:00  \n",
       "958593  2019-12-31  15:53:00  \n",
       "958594  2019-12-31  15:54:00  \n",
       "958595  2019-12-31  15:55:00  \n",
       "\n",
       "[958596 rows x 8 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "95194434-61b3-4881-8aa5-b793031f552d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3325032303.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[105], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    plot data\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# plot data\n",
    "# Compute realized volatility (square root of RV), scale to percent\n",
    "daily[\"realized_vol_pct\"] = np.sqrt(daily[\"rv\"]) * 100\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(daily[\"day\"], daily[\"realized_vol_pct\"], lw=0.8, color=\"steelblue\")\n",
    "plt.title(\"Daily Realized Volatility (IBM, %)\")\n",
    "plt.ylabel(\"Volatility (%)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
